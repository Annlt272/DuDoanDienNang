import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import torch
from torch import nn
from sklearn.preprocessing import StandardScaler
import os
import gc
import time
import joblib

# --- C·∫•u h√¨nh ---
DATA_PATH = "E:\\Demo\\TIMESERIES\\Data1.csv"
MODEL_DIR = "models"
MAX_HOUSEHOLDS = 5
DATE_MIN = datetime(2011, 12, 1)
DATE_MAX = datetime(2014, 2, 28)

# --- Thi·∫øt b·ªã ---
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- C√°c b∆∞·ªõc d·ª± b√°o multi-step ---
forecast_steps_map = {
    "1 gi·ªù": 2,
    "1 ng√†y": 48
}

# --- ƒê·ªô d√†i chu·ªói ƒë·∫ßu v√†o t∆∞∆°ng ·ª©ng ---
seq_len_map = {
    "1 gi·ªù": 48,
    "1 ng√†y": 336
}

# --- M√¥ h√¨nh LSTM ---
class LSTMModel(nn.Module):
    def __init__(self, input_size=1, hidden_dim=64, output_dim=48):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)
        self.dropout = nn.Dropout(0.2)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x, _ = self.lstm(x)
        x = self.dropout(x[:, -1, :])
        return self.fc(x)

# --- X·ª≠ l√Ω chu·ªói 0 d√†i ---
def clean_long_zero_sequences(series, threshold=6):
    zero_mask = (series == 0)
    group = (zero_mask != zero_mask.shift()).cumsum()
    counts = zero_mask.groupby(group).transform("sum")
    to_nan = (zero_mask & (counts >= threshold))
    series_cleaned = series.copy()
    series_cleaned[to_nan] = np.nan
    return series_cleaned.interpolate(method="linear").ffill().bfill()

# --- Load d·ªØ li·ªáu ---
@st.cache_data(show_spinner=False)
def load_full_data(path):
    chunks = pd.read_csv(path, sep=';', engine="c", chunksize=95_000, on_bad_lines='skip')
    df_list = []
    for chunk in chunks:
        chunk.columns = chunk.columns.str.strip()
        if "KWH/hh (per half hour)" in chunk.columns:
            chunk["KWH/hh (per half hour)"] = pd.to_numeric(
                chunk["KWH/hh (per half hour)"].astype(str).str.replace(",", "."), errors='coerce')
        df_list.append(chunk)

    df = pd.concat(df_list, ignore_index=True)
    del df_list, chunks
    gc.collect()

    df.dropna(subset=["LCLid", "stdorToU", "DateTime", "KWH/hh (per half hour)"], inplace=True)
    df["DateTime"] = pd.to_datetime(df["DateTime"], dayfirst=True, errors='coerce')
    df.dropna(subset=["DateTime"], inplace=True)
    df.set_index("DateTime", inplace=True)

    return df[(df.index >= DATE_MIN) & (df.index <= DATE_MAX)]

@st.cache_data(show_spinner=False)
def load_available_households(df):
    return sorted(df["LCLid"].unique())

# --- X·ª≠ l√Ω d·ªØ li·ªáu h·ªô ---
def get_household_data(df, household_id, start_date, end_date):
    df_house = df[df["LCLid"] == household_id]
    df_house = df_house[(df_house.index >= pd.to_datetime(start_date)) & (df_house.index <= pd.to_datetime(end_date))]
    if df_house.empty:
        return None
    ts = df_house["KWH/hh (per half hour)"].resample("30min").mean().ffill()
    ts = ts[ts >= 0]  # B·ªè gi√° tr·ªã √¢m
    ts = clean_long_zero_sequences(ts)  # L√†m s·∫°ch chu·ªói 0 d√†i
    ts = ts.clip(upper=ts.quantile(0.995))  # Lo·∫°i outlier
    return ts

# --- Chu·∫©n b·ªã chu·ªói ƒë·∫ßu v√†o ---
def prepare_sequence(series, seq_len):
    values = series.values.reshape(-1, 1)
    if len(values) < seq_len:
        return None, None
    return values[-seq_len:], None

# --- Load m√¥ h√¨nh + scaler ---
def load_model_and_scaler(household_id, label):
    folder_name = f"{household_id}_{label}"
    folder_path = os.path.join(MODEL_DIR, folder_name)
    model_path = os.path.join(folder_path, "final_model.pt")
    scaler_path = os.path.join(folder_path, "scaler.save")

    if not os.path.exists(model_path) or not os.path.exists(scaler_path):
        return None, None

    forecast_steps = forecast_steps_map[label]
    model = LSTMModel(output_dim=forecast_steps).to(device)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    scaler = joblib.load(scaler_path)

    return model, scaler

# --- D·ª± b√°o ---
def forecast_multi_step(model, input_seq, scaler, seq_len):
    scaled = scaler.transform(input_seq)
    input_tensor = torch.tensor(scaled.reshape(1, seq_len, 1), dtype=torch.float32).to(device)
    with torch.no_grad():
        output = model(input_tensor).cpu().numpy().reshape(-1, 1)
    return scaler.inverse_transform(output).flatten()

# --- Giao di·ªán ---
st.set_page_config(page_title="D·ª± b√°o ƒëi·ªán", layout="wide")
st.title("D·ª∞ B√ÅO ƒêI·ªÜN NƒÇNG TI√äU TH·ª§")

with st.spinner("üì¶ ƒêang t·∫£i d·ªØ li·ªáu..."):
    full_df = load_full_data(DATA_PATH)
    households = load_available_households(full_df)

selected_households = st.multiselect("Ch·ªçn h·ªô gia ƒë√¨nh", households, max_selections=MAX_HOUSEHOLDS)

start_date = st.date_input("T·ª´ ng√†y", datetime(2011, 12, 1), min_value=DATE_MIN, max_value=DATE_MAX)
end_date = st.date_input("ƒê·∫øn ng√†y", datetime(2014, 2, 28), min_value=DATE_MIN, max_value=DATE_MAX)

if start_date > end_date:
    st.warning("‚ùó Ng√†y b·∫Øt ƒë·∫ßu ph·∫£i tr∆∞·ªõc ng√†y k·∫øt th√∫c.")
    st.stop()

forecast_label = st.selectbox("Kho·∫£ng th·ªùi gian d·ª± b√°o", list(forecast_steps_map.keys()))

if st.button("D·ª± b√°o"):
    if not selected_households:
        st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 h·ªô.")
        st.stop()

    seq_len = seq_len_map[forecast_label]

    for hid in selected_households:
        st.subheader(f"{hid}")
        start = time.time()

        ts = get_household_data(full_df, hid, start_date, end_date)
        if ts is None or len(ts) < seq_len:
            st.warning("Kh√¥ng ƒë·ªß d·ªØ li·ªáu.")
            continue

        input_seq, _ = prepare_sequence(ts, seq_len)
        if input_seq is None:
            st.warning("Chu·ªói ƒë·∫ßu v√†o kh√¥ng h·ª£p l·ªá.")
            continue

        model, scaler = load_model_and_scaler(hid, forecast_label)
        if model is None or scaler is None:
            st.warning("Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ph√π h·ª£p.")
            continue

        preds = forecast_multi_step(model, input_seq, scaler, seq_len)
        future_index = [ts.index[-1] + timedelta(minutes=30 * (i + 1)) for i in range(len(preds))]

        forecast_df = pd.DataFrame({
            "Th·ªùi gian": future_index,
            "D·ª± b√°o (kWh)": preds
        }).set_index("Th·ªùi gian")

        st.line_chart(forecast_df)

        end = time.time()
        st.success(f"D·ª± b√°o ho√†n th√†nh trong {end - start:.2f} gi√¢y.")



# cd /d e:\Demo\TIMESERIES
# streamlit run GD_demo.py

