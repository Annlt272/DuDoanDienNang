{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aefe1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# --- C·∫•u h√¨nh ---\n",
    "DATA_PATH = \"E:\\\\Demo\\\\TIMESERIES\\\\Data1.csv\"\n",
    "MODEL_DIR = \"models\"\n",
    "DATE_MIN = datetime(2011, 12, 1)\n",
    "DATE_MAX = datetime(2014, 2, 28)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Map c·∫•u h√¨nh hu·∫•n luy·ªán ---\n",
    "config_map = {\n",
    "    \"1 ng√†y (1d)\": {\"forecast_steps\": 48, \"seq_len\": 336, \"suffix\": \"1d\"},\n",
    "    \"1 gi·ªù (1h)\": {\"forecast_steps\": 2, \"seq_len\": 48, \"suffix\": \"1h\"}\n",
    "}\n",
    "\n",
    "# --- Model ---\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_dim=64, output_dim=48):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x[:, -1, :])\n",
    "        return self.fc(x)\n",
    "\n",
    "# --- Ti·ªÅn x·ª≠ l√Ω ---\n",
    "def clean_long_zero_sequences(series, threshold=6):\n",
    "    zero_mask = (series == 0)\n",
    "    group = (zero_mask != zero_mask.shift()).cumsum()\n",
    "    counts = zero_mask.groupby(group).transform(\"sum\")\n",
    "    to_nan = (zero_mask & (counts >= threshold))\n",
    "    series_cleaned = series.copy()\n",
    "    series_cleaned[to_nan] = np.nan\n",
    "    return series_cleaned.interpolate().ffill().bfill()\n",
    "\n",
    "@st.cache_data(show_spinner=False)\n",
    "def load_data(path):\n",
    "    chunks = pd.read_csv(path, sep=';', engine=\"c\", chunksize=95_000, on_bad_lines='skip')\n",
    "    df_list = []\n",
    "    for chunk in chunks:\n",
    "        chunk.columns = chunk.columns.str.strip()\n",
    "        if \"KWH/hh (per half hour)\" in chunk.columns:\n",
    "            chunk[\"KWH/hh (per half hour)\"] = pd.to_numeric(\n",
    "                chunk[\"KWH/hh (per half hour)\"].astype(str).str.replace(\",\", \".\"), errors='coerce')\n",
    "        df_list.append(chunk)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    del df_list, chunks\n",
    "    gc.collect()\n",
    "    df.dropna(subset=[\"LCLid\", \"stdorToU\", \"DateTime\", \"KWH/hh (per half hour)\"], inplace=True)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], dayfirst=True, errors='coerce')\n",
    "    df.dropna(subset=[\"DateTime\"], inplace=True)\n",
    "    df.set_index(\"DateTime\", inplace=True)\n",
    "    return df[(df.index >= DATE_MIN) & (df.index <= DATE_MAX)]\n",
    "\n",
    "def get_household_series(df, household_id):\n",
    "    df_house = df[df[\"LCLid\"] == household_id]\n",
    "    ts = df_house[\"KWH/hh (per half hour)\"].resample(\"30min\").mean().ffill()\n",
    "    ts = ts[ts >= 0]\n",
    "    ts = clean_long_zero_sequences(ts)\n",
    "    ts = ts.clip(upper=ts.quantile(0.995))\n",
    "    return ts\n",
    "\n",
    "def create_sequences(series, seq_len, forecast_steps):\n",
    "    values = series.values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled) - seq_len - forecast_steps + 1):\n",
    "        X.append(scaled[i:i+seq_len])\n",
    "        y.append(scaled[i+seq_len:i+seq_len+forecast_steps].flatten())\n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "def train_model(X_train, y_train, output_dim, epochs=10, lr=0.001):\n",
    "    model = LSTMModel(output_dim=output_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        st.write(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.5f}\")\n",
    "    return model\n",
    "\n",
    "# --- Giao di·ªán ---\n",
    "st.set_page_config(page_title=\"Hu·∫•n luy·ªán m√¥ h√¨nh\", layout=\"wide\")\n",
    "st.title(\"üéØ HU·∫§N LUY·ªÜN M√î H√åNH LSTM D·ª∞ B√ÅO ƒêI·ªÜN\")\n",
    "\n",
    "with st.spinner(\"ƒêang t·∫£i d·ªØ li·ªáu...\"):\n",
    "    df = load_data(DATA_PATH)\n",
    "    household_ids = sorted(df[\"LCLid\"].unique())\n",
    "\n",
    "selected_household = st.selectbox(\"Ch·ªçn h·ªô gia ƒë√¨nh\", household_ids)\n",
    "selected_label = st.selectbox(\"Ch·ªçn kho·∫£ng d·ª± b√°o\", list(config_map.keys()))\n",
    "\n",
    "if st.button(\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán\"):\n",
    "    config = config_map[selected_label]\n",
    "    seq_len = config[\"seq_len\"]\n",
    "    forecast_steps = config[\"forecast_steps\"]\n",
    "    suffix = config[\"suffix\"]\n",
    "\n",
    "    st.write(\"Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "    ts = get_household_series(df, selected_household)\n",
    "\n",
    "    if len(ts) < seq_len + forecast_steps:\n",
    "        st.warning(\"Kh√¥ng ƒë·ªß d·ªØ li·ªáu cho hu·∫•n luy·ªán.\")\n",
    "        st.stop()\n",
    "\n",
    "    X, y, scaler = create_sequences(ts, seq_len, forecast_steps)\n",
    "    st.write(f\"T·ªïng s·ªë m·∫´u hu·∫•n luy·ªán: {len(X)}\")\n",
    "\n",
    "    st.write(\"B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh...\")\n",
    "    start_time = time.time()\n",
    "    model = train_model(X, y, output_dim=forecast_steps, epochs=10, lr=0.001)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # L∆∞u model\n",
    "    folder_name = f\"{selected_household}_{suffix}\"\n",
    "    folder_path = os.path.join(MODEL_DIR, folder_name)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), os.path.join(folder_path, \"final_model.pt\"))\n",
    "    joblib.dump(scaler, os.path.join(folder_path, \"scaler.save\"))\n",
    "\n",
    "    st.success(f\"Hu·∫•n luy·ªán v√† l∆∞u model ho√†n t·∫•t sau {end_time - start_time:.2f} gi√¢y.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51b01bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç B·∫£ng ƒë√°nh gi√° m√¥ h√¨nh (1 ng√†y d·ª± b√°o):\n",
      "                       MAE          RMSE      MAPE (%)      R¬≤ Score\n",
      "Household ID                                                        \n",
      "MAC000034     7.348850e+06  1.691480e+07  4.978489e+05  2.740000e-02\n",
      "MAC000049     2.408512e+06  4.774701e+06  4.365747e+05 -2.400000e-03\n",
      "MAC000003     5.149548e+05  6.435414e+05  8.423354e+05 -4.853520e+06\n",
      "MAC000024     2.244899e+06  5.178887e+06  2.797869e+06  1.288000e-01\n",
      "MAC000032     1.325518e+06  2.673469e+06  6.783820e+14  1.493000e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ƒê√°nh gi√° m√¥ h√¨nh\n",
    "metrics = {}\n",
    "\n",
    "for household_id, result in forecast_results.items():\n",
    "    if isinstance(result, tuple):\n",
    "        actual, forecast = result\n",
    "        mae = mean_absolute_error(actual, forecast)\n",
    "        rmse = np.sqrt(mean_squared_error(actual, forecast))\n",
    "        mape = np.mean(np.abs((actual - forecast) / (actual + 1e-8))) * 100  # tr√°nh chia cho 0\n",
    "        r2 = r2_score(actual, forecast)\n",
    "\n",
    "        metrics[household_id] = {\n",
    "            \"MAE\": mae,\n",
    "            \"RMSE\": rmse,\n",
    "            \"MAPE (%)\": mape,\n",
    "            \"R¬≤ Score\": r2\n",
    "        }\n",
    "\n",
    "# Hi·ªÉn th·ªã b·∫£ng ƒë√°nh gi√°\n",
    "metrics_df = pd.DataFrame(metrics).T  # Transpose ƒë·ªÉ h√†ng l√† h·ªô\n",
    "metrics_df.index.name = \"Household ID\"\n",
    "\n",
    "print(\"\\nüîç B·∫£ng ƒë√°nh gi√° m√¥ h√¨nh (1 ng√†y d·ª± b√°o):\")\n",
    "print(metrics_df.round(4))\n",
    "\n",
    "# (Tu·ª≥ ch·ªçn) L∆∞u ra file CSV\n",
    "# metrics_df.to_csv(\"evaluation_metrics_1d.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1890ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì so s√°nh th·ª±c t·∫ø v√† d·ª± b√°o cho c√°c h·ªô\n",
    "def plot_forecast_results(forecast_results, forecast_label=\"1d\"):\n",
    "    step = forecast_steps_map[forecast_label][\"steps\"]\n",
    "    num_plots = len(forecast_results)\n",
    "    fig, axes = plt.subplots(num_plots, 1, figsize=(12, 3 * num_plots), sharex=True)\n",
    "\n",
    "    if num_plots == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, (hid, data) in zip(axes, forecast_results.items()):\n",
    "        if isinstance(data, str):\n",
    "            ax.text(0.5, 0.5, f\"L·ªói: {data}\", ha='center', va='center', fontsize=12)\n",
    "            ax.set_title(f\"H·ªô {hid}\")\n",
    "            continue\n",
    "\n",
    "        actual, forecast = data\n",
    "        ax.plot(actual, label=\"Th·ª±c t·∫ø\", marker='o')\n",
    "        ax.plot(forecast, label=\"D·ª± b√°o\", marker='x', linestyle='--')\n",
    "        ax.set_title(f\"H·ªô: {hid}\")\n",
    "        ax.set_ylabel(\"KWh\")\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Khung gi·ªù (30 ph√∫t)\")\n",
    "    plt.suptitle(\"So s√°nh th·ª±c t·∫ø v√† d·ª± b√°o\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.show()\n",
    "\n",
    "# G·ªçi h√†m v·∫Ω\n",
    "plot_forecast_results(forecast_results, forecast_label=\"1d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "# --- C·∫•u h√¨nh ---\n",
    "DATA_PATH = \"E:\\\\Demo\\\\TIMESERIES\\\\Data1.csv\"\n",
    "MODEL_DIR = \"models\"\n",
    "DATE_MIN = datetime(2011, 12, 1)\n",
    "DATE_MAX = datetime(2014, 2, 28)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Tham s·ªë hu·∫•n luy·ªán ---\n",
    "household_id = \"MAC000002\"  # H·ªô gia ƒë√¨nh c·∫ßn train\n",
    "forecast_type = \"1h\"  # Ch·ªçn '1d' (1 ng√†y) ho·∫∑c '1h' (1 gi·ªù)\n",
    "EPOCHS = 10\n",
    "LR = 0.001\n",
    "\n",
    "# --- C·∫•u h√¨nh theo lo·∫°i d·ª± b√°o ---\n",
    "if forecast_type == \"1d\":\n",
    "    forecast_steps = 48\n",
    "    seq_len = 336\n",
    "elif forecast_type == \"1h\":\n",
    "    forecast_steps = 2\n",
    "    seq_len = 48\n",
    "else:\n",
    "    raise ValueError(\"Ch·ªâ ch·∫•p nh·∫≠n '1d' ho·∫∑c '1h'!\")\n",
    "\n",
    "# --- Model ---\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_dim=64, output_dim=48):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x[:, -1, :])\n",
    "        return self.fc(x)\n",
    "\n",
    "# --- Ti·ªÅn x·ª≠ l√Ω ---\n",
    "def clean_long_zero_sequences(series, threshold=6):\n",
    "    zero_mask = (series == 0)\n",
    "    group = (zero_mask != zero_mask.shift()).cumsum()\n",
    "    counts = zero_mask.groupby(group).transform(\"sum\")\n",
    "    to_nan = (zero_mask & (counts >= threshold))\n",
    "    series_cleaned = series.copy()\n",
    "    series_cleaned[to_nan] = np.nan\n",
    "    return series_cleaned.interpolate().ffill().bfill()\n",
    "\n",
    "def load_data(path):\n",
    "    chunks = pd.read_csv(path, sep=';', engine=\"c\", chunksize=95_000, on_bad_lines='skip')\n",
    "    df_list = []\n",
    "    for chunk in chunks:\n",
    "        chunk.columns = chunk.columns.str.strip()\n",
    "        if \"KWH/hh (per half hour)\" in chunk.columns:\n",
    "            chunk[\"KWH/hh (per half hour)\"] = pd.to_numeric(\n",
    "                chunk[\"KWH/hh (per half hour)\"].astype(str).str.replace(\",\", \".\"), errors='coerce')\n",
    "        df_list.append(chunk)\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    del df_list, chunks\n",
    "    gc.collect()\n",
    "    df.dropna(subset=[\"LCLid\", \"stdorToU\", \"DateTime\", \"KWH/hh (per half hour)\"], inplace=True)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"], dayfirst=True, errors='coerce')\n",
    "    df.dropna(subset=[\"DateTime\"], inplace=True)\n",
    "    df.set_index(\"DateTime\", inplace=True)\n",
    "    return df[(df.index >= DATE_MIN) & (df.index <= DATE_MAX)]\n",
    "\n",
    "def get_household_series(df, household_id):\n",
    "    df_house = df[df[\"LCLid\"] == household_id]\n",
    "    ts = df_house[\"KWH/hh (per half hour)\"].resample(\"30min\").mean().ffill()\n",
    "    ts = ts[ts >= 0]\n",
    "    ts = clean_long_zero_sequences(ts)\n",
    "    ts = ts.clip(upper=ts.quantile(0.995))\n",
    "    return ts\n",
    "\n",
    "def create_sequences(series, seq_len, forecast_steps):\n",
    "    values = series.values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled) - seq_len - forecast_steps + 1):\n",
    "        X.append(scaled[i:i+seq_len])\n",
    "        y.append(scaled[i+seq_len:i+seq_len+forecast_steps].flatten())\n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "def train_model(X_train, y_train, output_dim, epochs, lr):\n",
    "    model = LSTMModel(output_dim=output_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.5f}\")\n",
    "    return model\n",
    "\n",
    "# --- Ch·∫°y hu·∫•n luy·ªán ---\n",
    "print(\"=== B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN ===\")\n",
    "\n",
    "print(\"ƒêang load d·ªØ li·ªáu...\")\n",
    "df = load_data(DATA_PATH)\n",
    "\n",
    "print(\"Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "ts = get_household_series(df, household_id)\n",
    "\n",
    "if len(ts) < seq_len + forecast_steps:\n",
    "    raise ValueError(\"Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ hu·∫•n luy·ªán!\")\n",
    "\n",
    "X, y, scaler = create_sequences(ts, seq_len, forecast_steps)\n",
    "print(f\"S·ªë l∆∞·ª£ng m·∫´u train: {len(X)}\")\n",
    "\n",
    "print(\"ƒêang hu·∫•n luy·ªán...\")\n",
    "start_time = time.time()\n",
    "model = train_model(X, y, output_dim=forecast_steps, epochs=EPOCHS, lr=LR)\n",
    "end_time = time.time()\n",
    "\n",
    "# --- L∆∞u model ---\n",
    "folder_name = f\"{household_id}_{forecast_type}\"\n",
    "folder_path = os.path.join(MODEL_DIR, folder_name)\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "torch.save(model.state_dict(), os.path.join(folder_path, \"final_model.pt\"))\n",
    "joblib.dump(scaler, os.path.join(folder_path, \"scaler.save\"))\n",
    "\n",
    "print(f\"Hu·∫•n luy·ªán v√† l∆∞u model ho√†n t·∫•t sau {end_time - start_time:.2f} gi√¢y.\")\n",
    "print(f\"Model l∆∞u t·∫°i: {folder_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
