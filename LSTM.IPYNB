{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e7146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BẮT ĐẦU HUẤN LUYỆN TOÀN BỘ 12 GIỜ ===\n",
      "[MAC000002] Đang xử lý...\n",
      "[MAC000002] Số mẫu huấn luyện: 27673\n",
      "  Epoch 1, Loss: 0.01396\n",
      "  Epoch 2, Loss: 0.01162\n",
      "  Epoch 3, Loss: 0.01120\n",
      "  Epoch 4, Loss: 0.01034\n",
      "  Epoch 5, Loss: 0.00979\n",
      "  Epoch 6, Loss: 0.00955\n",
      "  Epoch 7, Loss: 0.00941\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "from torch import nn\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- Cấu hình ---\n",
    "DATA_PATH = \"E:\\\\Demo\\\\TIMESERIES\\\\Data1.csv\"  # Đường dẫn tới file dữ liệu của bạn\n",
    "MODEL_DIR = \"models\"\n",
    "DATE_MIN = datetime(2011, 12, 1)\n",
    "DATE_MAX = datetime(2014, 2, 28)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "EPOCHS = 50\n",
    "LR = 0.001\n",
    "\n",
    "# --- Mô hình LSTM ---\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_dim=64, output_dim=24):  # 24 bước dự báo (12 giờ)\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.dropout(x[:, -1, :])\n",
    "        return self.fc(x)\n",
    "\n",
    "# --- Tiền xử lý ---\n",
    "def clean_long_zero_sequences(series, threshold=6):\n",
    "    zero_mask = (series == 0)\n",
    "    group = (zero_mask != zero_mask.shift()).cumsum()\n",
    "    counts = zero_mask.groupby(group).transform(\"sum\")\n",
    "    to_nan = (zero_mask & (counts >= threshold))\n",
    "    series_cleaned = series.copy()\n",
    "    series_cleaned[to_nan] = np.nan\n",
    "    return series_cleaned.interpolate().ffill().bfill()\n",
    "\n",
    "def get_household_series_from_chunks(csv_path, household_id):\n",
    "    chunks = pd.read_csv(csv_path, sep=';', chunksize=100_000, on_bad_lines='skip')\n",
    "    df_list = []\n",
    "    for chunk in chunks:\n",
    "        chunk.columns = chunk.columns.str.strip()\n",
    "        if \"KWH/hh (per half hour)\" not in chunk.columns:\n",
    "            continue\n",
    "        chunk = chunk[chunk[\"LCLid\"] == household_id]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "        chunk[\"KWH/hh (per half hour)\"] = pd.to_numeric(\n",
    "            chunk[\"KWH/hh (per half hour)\"].astype(str).str.replace(\",\", \".\"), errors='coerce')\n",
    "        chunk[\"DateTime\"] = pd.to_datetime(chunk[\"DateTime\"], dayfirst=True, errors='coerce')\n",
    "        chunk.dropna(subset=[\"DateTime\"], inplace=True)\n",
    "        chunk = chunk[(chunk[\"DateTime\"] >= DATE_MIN) & (chunk[\"DateTime\"] <= DATE_MAX)]\n",
    "        df_list.append(chunk)\n",
    "    if not df_list:\n",
    "        return None\n",
    "    df = pd.concat(df_list)\n",
    "    df.set_index(\"DateTime\", inplace=True)\n",
    "    ts = df[\"KWH/hh (per half hour)\"].resample(\"30min\").mean().ffill()\n",
    "    ts = ts[ts >= 0]\n",
    "    ts = clean_long_zero_sequences(ts)\n",
    "    ts = ts.clip(upper=ts.quantile(0.995))\n",
    "    return ts\n",
    "\n",
    "def create_sequences(series, seq_len, forecast_steps):\n",
    "    values = series.values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(values)\n",
    "    X, y = [], []\n",
    "    for i in range(len(scaled) - seq_len - forecast_steps + 1):\n",
    "        X.append(scaled[i:i+seq_len])\n",
    "        y.append(scaled[i+seq_len:i+seq_len+forecast_steps].flatten())\n",
    "    return np.array(X), np.array(y), scaler\n",
    "\n",
    "def train_model(X_train, y_train, output_dim, epochs, lr):\n",
    "    model = LSTMModel(output_dim=output_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_X, batch_y in loader:\n",
    "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_X)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"  Epoch {epoch+1}, Loss: {total_loss/len(loader):.5f}\")\n",
    "    return model\n",
    "\n",
    "def full_training_pipeline(csv_path, household_id):\n",
    "    forecast_steps = 24  # 12 giờ\n",
    "    seq_len = 336        # 7 ngày quan sát\n",
    "\n",
    "    folder_name = f\"{household_id}_12h\"\n",
    "    folder_path = os.path.join(MODEL_DIR, folder_name)\n",
    "    model_file = os.path.join(folder_path, \"final_model.pt\")\n",
    "    if os.path.exists(model_file):\n",
    "        print(f\"[{household_id}] Đã có model, bỏ qua.\")\n",
    "        return\n",
    "\n",
    "    print(f\"[{household_id}] Đang xử lý...\")\n",
    "\n",
    "    ts = get_household_series_from_chunks(csv_path, household_id)\n",
    "    if ts is None or len(ts) < seq_len + forecast_steps:\n",
    "        print(f\"[{household_id}] Không đủ dữ liệu.\")\n",
    "        return\n",
    "\n",
    "    X, y, scaler = create_sequences(ts, seq_len, forecast_steps)\n",
    "    print(f\"[{household_id}] Số mẫu huấn luyện: {len(X)}\")\n",
    "\n",
    "    model = train_model(X, y, output_dim=forecast_steps, epochs=EPOCHS, lr=LR)\n",
    "\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    joblib.dump(scaler, os.path.join(folder_path, \"scaler.save\"))\n",
    "    print(f\"[{household_id}] Đã lưu model.\")\n",
    "\n",
    "# --- Chạy toàn bộ ---\n",
    "print(\"=== BẮT ĐẦU HUẤN LUYỆN TOÀN BỘ 12 GIỜ ===\")\n",
    "\n",
    "# Lấy danh sách các hộ\n",
    "household_ids = set()\n",
    "chunks = pd.read_csv(DATA_PATH, sep=\";\", chunksize=100_000, on_bad_lines='skip', usecols=[\"LCLid\"])\n",
    "for chunk in chunks:\n",
    "    chunk.columns = chunk.columns.str.strip()\n",
    "    household_ids.update(chunk[\"LCLid\"].dropna().unique())\n",
    "\n",
    "household_ids = sorted(household_ids)\n",
    "\n",
    "# Train từng hộ\n",
    "for household_id in household_ids:\n",
    "    try:\n",
    "        full_training_pipeline(DATA_PATH, household_id)\n",
    "    except Exception as e:\n",
    "        print(f\"[{household_id}] Lỗi: {e}\")\n",
    "\n",
    "print(\"=== HOÀN TẤT TOÀN BỘ ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
